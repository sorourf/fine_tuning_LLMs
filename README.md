# fine_tuning_LLMs

# LLaMA Fine-Tuning for Sentiment Analysis

This project demonstrates how to fine-tune a LLaMA model for sentiment analysis using the Hugging Face Transformers library and the PEFT (Parameter-Efficient Fine-Tuning) method.

## Getting Started

1. Clone this repository.
2. Install the required packages: `pip install transformers peft trl datasets scikit-learn`
3. Open the `llama_fine_tuning_sentiment_analysis.ipynb` notebook in Jupyter or Google Colab.
4. Follow the instructions in the notebook to fine-tune the model and run inference.

## Requirements

- Python 3.7+
- PyTorch 1.10+
- Transformers 4.25+
- PEFT 0.3.0+
- Datasets 2.10+
- Scikit-learn 1.0+

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
